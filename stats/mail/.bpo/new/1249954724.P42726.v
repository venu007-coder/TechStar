Return-Path: ramsubramaniann@gmail.com
Received: from mx104.stngva01.us.mxservers.net (198.173.112.41)
	by mail19f.g19.rapidsite.net (RS ver 1.0.95vs) with SMTP id 2-0627594722
	for <bpojobs@altechstar.com>; Mon, 10 Aug 2009 21:38:42 -0400 (EDT)
Received: from unknown [74.86.158.36] (EHLO stork.arvixe.com)
	by va1-mx104.stngva01.us.mxservers.net (mxl_mta-3.1.0-05)
	with ESMTP id 2abc08a4.2687736736.399764.00-001.va1-mx104.stngva01.us.mxservers.net (envelope-from <ramsubramaniian@gmail.com>);
	Mon, 10 Aug 2009 21:38:42 -0400 (EDT)
Received: from [59.93.74.218] (helo=GOV)
	by stork.arvixe.com with esmtpa (Exim 4.69)
	(envelope-from <ramsubramaniian@gmail.com>)
	id 1MagJz-0001nq-P0
	for bpojobs@altechstar.com; Mon, 10 Aug 2009 18:38:41 -0700
Reply-To: ramsubramaniann@gmail.com
Message-ID: <0d88d042b9d510c20a1cd4c70013241e@gmail.com>
From: "Ram Subr" <ramsubramaniian@gmail.com>
To: <bpojobs@altechstar.com>
Subject: =?windows-1252?Q?Sr._Datastage_Analyst/Developer_with_Teradata_experience_available_for_contracts.?=
Date: Mon, 10 Aug 2009 21:34:57 -0400
MIME-Version: 1.0
Content-Type: text/plain;
	charset="windows-1252"
Content-Transfer-Encoding: quoted-printable
X-AntiAbuse: This header was added to track abuse, please include it with any abuse report
X-AntiAbuse: Primary Hostname - stork.arvixe.com
X-AntiAbuse: Original Domain - altechstar.com
X-AntiAbuse: Originator/Caller UID/GID - [47 12] / [47 12]
X-AntiAbuse: Sender Address Domain - gmail.com
X-Spam: [F=0.2000000000; B=0.500(0); S=0.200(2009071501); MH=0.500(2009081026)]
X-MAIL-FROM: <ramsubramaniian@gmail.com>
X-SOURCE-IP: [74.86.158.36]
X-SF-Loop: 1

Hi,

I am a Senior ETL analyst with Expert experience in IT and extensive ETL =
tool experience using IBM Websphere Datastage (8.x/7.5.x/7.0/6.0), =
Parallel Extender and Quality Stage=2E
=95  Expertise in data warehousing and data migration, data modeling, data =
validation and extracting data from legacy systems, =
Teradata/Oracle/DB2/SQL Server Databases.=20

I hold a valid H1B visa=2E
I am looking for corp to corp contracts only, I am not interested in =
transferring my visa=2E

I am located in DE=2E
I am ready to relocate anywhere in US=2E

Please get back to me, if you need someone with my skills=2E

Thanks,

Ram
                                                                           =
           =20
                                                     =20
                                                                           =
                                        Resume=20
                                                                           =
                                         RAM S
                                                                           =
                           ramsubramaniann@gmail.com
SUMMARY
=95	A Senior ETL analyst with Expert experience in IT and extensive ETL =
tool experience using IBM Websphere Datastage (8.x/7.5.x/7.0/6.0), =
Parallel Extender and Quality Stage=20
=95	Expertise in data warehousing and data migration, data modeling, data =
validation and extracting data from legacy systems, =
Teradata/Oracle/DB2/SQL Server Databases.=20
=95	Extensive knowledge of gathering business requirements, documenting =
them, and converting them into robust system designs. Experience in =
documenting high level design and the detail design per the=20
              requirements.=20
=95	Experience in evolving strategies and developing architecture for =
building a data warehouse and designing with implementation of Star, =
Snowflake schemas and multi-dimensional modeling.=20
=95	Experience in DataStage Parallel Extender (Formerly known as DataStage =
PX) for Parallel Processing  to improve job performance while working with =
bulk data=20
=95	Experience in development of parallel jobs on Parallel Extender =
framework for high volume data processing on multiple nodes.=20
=95	Experience in tuning parallel jobs and deciding partitioning =
strategies etc, and development and debugging skills.=20
=95	Tuned Jobs using various configurations by understanding it=92s =
complexity during volume testing before moving to production.=20
=95	Proficient in automating routine tasks using Unix Shell Scripts and =
Korn Shell scripts.=20
=95	Experience in integration of various data source like Oracle, =
Informix, Teradata, DB2, SQL Server, and MS Access onto staging area.=20
=95	Experience in writing the BTEQ scripts and using other Teradata =
utilities as FastLoad, MultiLoad and Fast-Export in loading the data from =
various sources to the target databases.=20
=95	Experience in writing, testing, and implementation of the Triggers, =
Procedures, Functions at Database level and form level using PL/SQL.=20
=95	Proficient in interacting with business users to identify information =
needs and initiating process changes, gathering requirements and authoring =
Use Cases, Use Case diagrams, Sequence diagrams, Activity=20
              Diagrams based on UML methodology using CASE tools like =
Erwin and knowledge about Clear case UCM and experience building the Case =
Management Systems.=20
=95	Retrieved Data from the datamarts and developed reports using tools =
like Cognos and exposure to Business Objects.=20
=95	Excellent analytical, communication and interpersonal skills=2E

Technical Skills
Data Warehousing : IBM WebSphere 8.x/7.x/6.x DATASTAGE =96 Designer, =
Director, Manager, Administrator, Parallel Extender, Quality Stage, =
Quality Manager
Databases             : Oracle 10g/9i/8i/8.0, Informix, DB2, TERADATA, SQL =
Server, MS Access
Data Modeling       : Erwin, Designer 2000, Logical and Physical Data =
Modeling, Dimensional Data Modeling, Data Modeling, Star Schema Modeling, =
Snow-Flake Modeling, FACT and Dimension Tables
Operating System  : UNX Sun Solaris 9.0, HP Unix, Windows 98/2000/XP, =
Windows NT 4.0
Languages	: Shell Scripting, HTML, JavaScript, J2EE, PERL, C++, Visual =
Basic, SQL
Database Tools	: SQL/PLSQL, SQL* Plus, MLoad, FastLoad, BTEQ, SQL*Loader, =
TOAD, MS Query
Reporting  	: Cognos EP Series 7, MS Visio, Business Objects 6.5, Crystal =
Reports

Education & Professional Affiliation:=20
=95         Bachelor of Technology (Graduated with Distinction), =
Jawaharlal Nehru Technological University, INDIA
=95         Member of TDWI(The Data Warehousing Institute)

Projects Summary
Timken Steel, OH							Jan =9208 =96 Till Date
Sr. Datastage Analyst/Developer
Project: Supporting the data warehouse loads for Orders, Sales, Purchasing =
and Selling & Administration Data marts. The role also aimed at =
enhancements and the automation required for the existing processes. =
Consolidating the modifications per the business changes required and =
preparing new data processing procedures for each new production moves. =
Worked parallel on few other design and development projects. Configured =
and installed the upgraded version to DataStage 8.1 before the design and =
development for migration=2E

Responsibilities:
=95          Gathering the business requirements by interacting with users =
and the business team in identifying the business rules and documenting =
them.=20
=95          Documenting the technical design (high-level) and setting up =
a development layout plan and assigning the task series to the developers=2E
=95          Trained the offshore team and assigned the existing =
development tasks and scheduled queries to include the business changes =
and managed to get the status updates=2E
=95          Designed and developed the DataStage jobs and sequencers as =
per the mappings (with best practices), for extraction and transformation =
of data for the new and the existing sites (on version 7.5.2) per the=20
            standards for migration onto the version 8.1=2E
=95          Coordinated with the DBA team to implement physical models =
and to setup development, test, and also to fix server issues related in =
the production environment=2E
=95          Monitored the daily production data processing for the Orders =
and the Sales Data Warehouses and then loading this data into the Star =
schema - data mart=2E
=95          Monitored the Sales invoices loaded during the weekend, once =
a month for the Sales Warehouse, based on load schedule turns=2E
=95          Developed and tested the server routines to pick the correct =
part numbers for the entities and also to change the timestamp=2E
=95          Created the templates using the ODBC stage and jobs to read =
and validate the data before processing for the warehouse loads=2E
=95          Used Hash files in creating the jobs for data deletion for =
the actual and the budget entries and testing them before moving to =
production environment, as opposed to the manual deletion followed =
earlier=2E
=95          Analyzed and documented the data flow including the logic =
coded in the existing jobs and sequencers starting from data validation =
through the star load for the purchasing warehouse=2E
=95          Modified the jobs to remove the inconsistency and included =
them to run in sequencers before scheduling them based on the tentative =
file =96 arrival times=2E
=95          Created jobs using the stages like Change-Capture stage in =
comparing the data between the two sources and capture this onto a file =
for further analysis=2E
=95          Created jobs using the PX stages like Remove-duplicate, =
Funnel, Merge, Filter stages and tested the jobs with the Peek stage=2E
=95          Created efficient Unix Shell Scripts to run the DataStage =
codes required for the On-Time Delivery Management systems=2E
=95          Added new projects and assigned the user roles and =
permissions, via. Datastage administrator=2E
=95          Used Stages like Teradata API, Teradata Enterprise and =
Teradata MLoad for loading the transformed data into the target database =
(EDW).=20
=95          Created standards and wrote test plans, including multiple =
phases for all four data warehouses and streamlined the tasks to go for =
each of the individual data warehouse=2E
=95          Completed and documented the Unit testing and Integration =
testing using the test files and other interfaces, generated to compare =
this data with the production parameters to get the error counts before=20
            implementing them in production environment=2E
=95          Used Teradata performance monitor to monitor and check system =
status during production run.=20
Environment: IBM Websphere DataStage 7.5.2/8.1 (Designer, Director, =
Manager, and Administrator), MetaStage, Oracle 11i, Teradata, Informix, =
SAP BW, MSQuery, Tivoli, SQL/PLSQL, Brio, DS Version Control, Unix Shell =
Scripts, Autosys, HP UX, Windows NT, Citrix=2E

Assurant Health, WI						 Oct =9207 =96 Dec =9107
Sr. Datastage Developer/Analyst
Project: The project objective was to upgrade the existing ITG Time =
Management System to incorporate new business decisions and the affected =
mappings. Also, the role involved working on the current issues along with =
reducing the inconsistency in the production data=2E

Responsibilities:
=95          Gathering the requirements for implementing the business rule =
and mapping corresponding data=2E
=95          Documented an ETL design document with these requirements and =
validated them upon completion=2E
=95          Modifying the current jobs in the time-tracking system, to =
incorporate the business logic=2E
=95          Developing new Parallel jobs to populate new tables required =
with the Datastage Enterprise Edition=2E
=95          Using the stages like Change-Capture, Modify, Look-up and =
Remove Duplicate in modifying the jobs already developed to improve the =
performance and to meet the requirements=2E
=95          Documented the process descriptions and summarized the detail =
design for the codes developed and tested for the new data flow =
requirement=2E
=95          Developing various one-shot jobs to fix the issues and =
inconsistent data in production. Also, comparing the two data warehouses =
and minimizing the differences with comparison=2E
=95          Writing SQL scripts to populate new fields added to tables on =
a one-shot basis=2E
=95          Extensively used Teradata Loa Utilities such as Teradata =
FastLoad, MultiLoad for parallel loading in Data integrator Bulk loader =
options=2E
=95          Solving the problem associated with slowly-changing dimension =
for one of the dimension tables=2E
=95          Modified and corrected some of the Unix Shell Scripts being =
used for the production runs of the current insurance data loads=2E
=95          Unit Testing and System testing the individual and =
extract-transform-load jobs in sequence respectively and documented these =
test results for all interfaces=2E
=95          Migrating the code required for the project to QA and Model =
using Version Control
Environment: IBM DataStage 7.5x Parallel Extender, Oracle 10g, SQL Server, =
Teradata, Autosys, SQL/PLSQL, Golden, Shell Scripts, MS Source Safe, HP =
UX, Windows XP

Citizen=92s Bank, RI		                                                     =
                   Sept =9206 =96 Sep =9107
Datastage Developer/Analyst
Project: The objective of this project is to automate the process to =
receive data related to loans issued and serviced every month pertaining =
to mortgage business and do required mappings, validate and load in to the =
collateral database. Also compare the loans issued data with loans =
serviced every month and report missing and discrepancies. To analyze the =
exposure make interpretation based on the functional documentation, Basel =
II for credit-risk analysis and operational-risk analysis=2E
=20
Responsibilities:
=95          Requirements gathering and identifying business rules for =
data mappings and data validations from the subject matter experts (SME)=2E
=95          Worked with the Basel II technical specifications team to =
understand the functional documentation and prepare the technical details =
accordingly=2E
=95          Reviewing and developing the DataStage jobs and to validate =
the business processes with the relevant data and report exceptions=2E
=95          Redefined the functional document into the technical details =
with high granularity to initiate the development codes=2E
=95          Development of parallel jobs on Parallel Extender framework =
(DataStage Enterprise Edition)=2E
=95          Designed and developed Parallel jobs to extract data, clean, =
transform, and to load the target tables using the DataStage Designer=2E
=95          Fine tuning of jobs by following best design practices, =
configuration changes and best data partitioning/collecting methodologies =
to meet the project requirement=2E
=95          Automation of ETL processes using DataStage Job Sequencer, =
Job Control routines and Transform functions=2E
=95          Performing administrative tasks such as setting up users and =
privileges, Creating and maintaining DataStage Projects and timely Project =
cleanup=2E
=95          Used DataStage =96 Director to Run and Monitor and check for =
any errors in the Jobs after successful compilation=2E
=95          Development of processes for enterprise data cleansing and =
de-duplication using Data Quality Assessments. Match-Merge and =
Survivorship of business records=2E
=95          Develop and modify existing PL/SQL procedures, functions, =
packages and triggers for implementing business rules and transformation=2E
=95          Worked extensively with hashed files and designed them =
efficiently in order to improve the performance of the jobs=2E
=95          Extensively did Unit Testing and Integration Testing on Job =
level and job sequential level=2E
=95	Used Fast Load & Multi-load and other utilities for better =
performances, based on the environment and requirement.=20
=95	Prepared BTEQ scripts to run before or after the data loaded in Target =
tables in order to perform several operations on target tables=2E
Environment: IBM Websphere (Ascential) DataStage 7.5.1 Parallel Extender =
(Designer, Director, Manager, and Administrator), Oracle 9i, Teradata =
V2R5, SQL Server, Basel II, Toad, SQL, PL/SQL, UNIX Shell Scripts, Sun =
Solaris 9.0, Windows 2000/2003=2E

CNSI, Seattle, WA							 Nov=9205 =96 Aug=9206
Data Warehouse Developer/Analyst
Project: CNSI provides web-based system for Medicaid claims processing, =
Decision support and Business Intelligence and other services along with =
web-based integrated solution for creating and managing vital events. The =
project aimed at processing claims for the state of Washington and to =
advance the payments to the provider through federal support or the =
client. Migrated server jobs to parallel jobs as a part of improving the =
performance for higher data volume and reducing the errors=2E
Responsibilities:
=95          Involved in creating entity relational and dimensional =
relational data models using Data modeling tool Erwin=2E
=95          Designed the Target Schema definition and Extraction, =
Transformation and Loading (ETL) using Datastage=2E
=95          Addressed Data Quality issues before delivering integrated =
data to be used in decision support systems
=95          Mapped Data Items from Source Systems to the Target System=2E
=95          Used the Datastage Designer to develop processes for =
extracting, cleansing, transforming, integrating, and loading data into =
data warehouse database=2E
=95          Worked on programs for scheduling Data loading and =
transformations using Data Stage from legacy system to Oracle 9i using =
SQL* Loader and PL/SQL=2E
=95          Designed and developed PL/SQL Procedures and functions to =
create Summary tables=2E
=95          Exporting of DataStage Components & Packaging of Projects =
using DataStage Manager and to create backups
=95          Involved in source data analysis and data cleansing
=95          Extensively used Reject Link, Job Parameters, and Stage =
Variables in developing jobs
=95          Used DataStage Director Schedule and run server jobs and to =
resolve error conditions, job failures=2E
=95          Used AUTOSYS for scheduling and loading of jobs in UNIX=2E
=95          Developed complex SQL queries and executed them as Test Cases =
to check if the actual results match with the expected results=2E
=95          Adopted performance-tuning techniques to improve the ETL =
process=2E
Environment: Ascential DataStage 7.5x Enterprise, Server Edition, =
MetaStage, Quality Stage, Quality Manager, Oracle 9i, DB2 UDB, SQL/PLSQL, =
SQL*Loader, Korn Shell Scripts, Sun Solaris 9.0, Windows NT 4.0=2E

Target Corporation, Minneapolis, MN		    	                             Sep =
=9204 =96 Oct=9205
ETL/Datastage Consultant
Project: A real time DW project, EDW houses all the sales, financial data =
and metrics for Target Corp and is used to store and analyze costs, =
revenue and customer centric information. The EDW team provides hundreds =
of statistical and business analysts, marketing managers, and customers =
with next-day access to complete information on customers, retail sales, =
inventory, shipments and forecast. The scope is specific on migrating to =
new technologies for better performance, maintenance and scalability to =
reduce errors, providing real time data and upgrading records as =
transactions are completed. This DW project has significant involvement in =
data extraction and migration from/to variety of RDBMS. Currently, all the =
existing server jobs, software have been changed to DataStage Parallel =
Jobs=2E

Responsibilities:
=95	Worked closely with Project lead/Manager, Architects, and Data =
Modelers to understand the business process and functional requirements.=20
=95	Identifying the business rules to incorporate in the data transforms =
and flow to the data warehouse.=20
=95	Design and Develop Enterprise edition Jobs based on the =
specification.=20
=95	Developed and supported the Extraction, Transformation and Load =
process (ETL) for a data warehouse from various data sources using =
DataStage Designer.=20
=95	Used DataStage Manager for importing the source and target database =
schemas, importing and exporting jobs/projects, creating new job =
categories and table definitions.=20
=95	Writing the program specification for converting server Jobs to ETL =
specific jobs.=20
=95	Prepared the complete data mapping for all the migrated jobs.=20
=95	Designed and developed the Routines and Job Sequence for the ETL =
jobs.=20
=95	Prepared Specification Documents for DataStage Jobs.=20
=95	Involved in Unit testing and integration testing to compare data with =
production data.=20
=95	Experience in running jobs using Job Sequencers, Job Batches.=20
=95	Developed Parallel jobs using various stages like Join, Merge, Funnel, =
Lookup, Sort, Transformer, Copy, Remove Duplicate, Filter, Peek, Column =
Generator, Pivot and Aggregator stages for grouping and=20
              summarizing on key performance indicators used in decision =
support systems.=20
=95	Used the DataStage Director to run, schedule, monitor, and test the =
application on development, and to obtain the performance statistics.=20
=95	Worked on Different databases like Oracle, and SQL Server.=20
=95	Configured Oracle, SQL Server in DataStage for accessing and reading =
from database whereas configured Teradata in DataStage for accessing and =
writing to database.=20
=95	Worked with Data Stage Administrator to create/modify/delete projects =
and cleanup projects=2E
Environment: Ascential DataStage 7.0(Designer, Director, Manager, and =
Administrator), Oracle9i, SQL Server, Teradata V2R5, Windows XP, UNIX, =
Erwin=2E

Apollo Capital Investments Ltd, India			    	         	Jul =9103 =96 Aug =
=9104
Oracle Developer
Project: e-IBS (Precision) - Clearing & Settlement/ Back office system
Precision is a part of TCS=92 eIBS Product, which caters to the needs to =
brokerage firms, Professional clearing members & custodians=2E

Responsibilities:
=95	Understanding of the functionality of the Stock Exchange Clearing & =
Settlement System.=20
=95	Requirement Analysis of Equity Billing module, Payments, Financial =
Accounting and Professional Clearing Member Billing Modules.=20
=95	Identification of the areas to be fully parameterized in the billing =
module (brokerage Calculation) of Clearing and Settlement system.=20
=95	Low level design of the Billing, Payments and Financial Accounting =
modules of the Clearing and Settlement system of Back office system of =
Apollo Sindhoori Capital Investment Ltd.=20
=95	Development source code in Forms 4.5/5.0/6i, Reports 4.5/5.0/6i, =
Oracle Discoverer 3.2, Pro*C, PL/SQL for the Billing, Payments and =
Financial Accounting modules of the clearing and settlement system of=20
              Back office system of Apollo Sindhoori Capital Investment =
Ltd.=20
=95	Involved in writing application codes in PL/SQL and stored them in =
functions, stored procedures and database packages for easy =
maintainability and called them from the Forms libraries and database=20
              triggers.=20
=95	Design of the ER Diagrams, data models in Oracle Designer 6i for the =
development in Payments and Financial Accounting Module of the Back office =
system.=20
=95	Providing the off site support for acceptance testing for the Back =
office system of Apollo Sindhoori Capital Investment Ltd, Chennai=20
=95	User administration and User Privilege Setup=20
=95	Unit testing for Billing, Payments and Financial Accounting Modules.=20
=95	Preparation of the test cases for unit testing and system testing of =
back office system.=20
=95	Preparation of system test plans and System testing for back office =
system for the complete functionality=2E
Environment:  Unix Sun Solaris (Server 2.5), Windows NT, Win95, MS-DOS =
6.0, Oracle 8i/8.0, Oracle Developer 2000 (Oracle forms 6i/5.0/4.5, =
Reports 6i/5.0/4.5), Oracle Designer 2000 & Designer 6i, PL/SQL,=20
Unix Shell scripts, TOAD, VSS

Compubrain (India) Ltd, INDIA				          	   Jul =9102 =96 May =9103
Oracle Developer
Client: ASKI
Alumni Portal=20
This is an Alumni Portal for a Indian based client faculty of management =
studies. Requirement for developing a Data Warehouse for Alumni Management =
System that provides the functionality for loading all the information =
regarding the students, their technical project details etc=20

Role:
=95	Worked as a Software Analyst for providing Database System in =
estimating the software and hardware capabilities and feasibility studies=20
=95	Analyzed the existing data warehouse that has the data sources as =
source=20
=95	Verified the loads and involved in debugging process=20
=95	Developed interfaces using PL/SQL procedures and created packages to =
load data into targeted Oracle database=20
=95	Developed PL/SQL stored procedures, database triggers and created =
packages=20
=95	Using Erwin 4.1 created star schema for engineering data warehouse=20
=95	Provided support for the daily loads, dimension, structure building, =
and Monthly Close Issues and Hierarchy management=20
=95	Responsible for testing and validating target data, fixing invalid =
mappings, and testing stored procedures=20
=95	Reviewed/constructed DDL & PL/SQL scripts; created and maintained =
database objects including scripts to build database objects=20
=95	Modified the existing packages, procedures and functions across the =
client=92s requirements
Environment Oracle 7.3, ETL, Oracle Forms, Oracle Projects, SQL/PLSQL, =
Developer 2000, Windows 95, Unix 


